---
title: "HW2"
author: "Nathalie Fadel"
date: "10/3/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Problem 1
```{r}
library(tidyverse)
transit_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% #data import
janitor::clean_names() %>% #format variable names so they are all lowercase snake
select(line:entry, vending, ada) %>%  #keep only these variables
mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE)) #recode the entry variable

#These data aren't necessarily tidy as they are right now. Currently, there are 19 variables (columns) and 1868 rows. The variable names are all formatted the same way and some variables have been discarded, but the routes 1-11 variables don't say much about the dataset unless you already know that the more routes the station services, the more columns that station will have filled in. This is not a good way of organizing and expressing this data. 

nrow(distinct(transit_data, line, station_name)) #how many distinct stations are there? 465.
nrow(filter(distinct(transit_data, line, station_name, ada), ada == TRUE)) #how many stations are ada compliant? 84.
nrow(filter(transit_data, entry == TRUE, vending == "NO"))/nrow(filter(transit_data, vending == "NO")) #proportion of stations with entry but no vending machine = 0.377

transit_data_tidy = (gather(transit_data, key = route_number, value = route, route1:route11)) #new dataframe where route number and route name are two variables
transit_data_tidy

nrow(filter(distinct(transit_data_tidy, line, station_name, route), route == "A"))
#60 stations on the A line

nrow(filter(distinct(transit_data_tidy, line, station_name, route, ada), route == "A", ada == TRUE)) #of those 60, only 17 are ADA compliant. SAD!
```

#Problem 2
```{r}
library(readxl)
mr_trash_wheel = read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", "Mr. Trash Wheel", range = "A2:N338") %>% #import mr trash wheel datasheet from cell A2 to N258
janitor::clean_names() %>% #clean up names of variables
  filter(!is.na(dumpster)) %>% #filter out dumpster totals
  mutate(sports_balls = round(sports_balls)) %>% #round 
  mutate(sports_balls = as.integer(sports_balls)) #make it an integer

precip_data_2016 = read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", "2016 Precipitation", range = "A2:B14") %>%
  janitor::clean_names() %>%
  mutate(year = 2016) #add a year column
  
precip_data_2017 = read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", "2017 Precipitation", range = "A2:B14") %>%
  janitor::clean_names() %>%
  filter(!is.na(total)) %>% #filter out months with no data
  mutate(year = 2017) #add year column

precip_stack <- rbind(
  mutate(
    precip_data_2016, month = month.name), 
  mutate(
      precip_data_2017, month = month.name)) #make new dataset with 2016 and 2017 precipitation datasets stacked on top of each other, and change month number to month name

#Make these into inline code:

nrow(mr_trash_wheel) #285 observations
mr_trash_wheel %>% filter(year == "2016") %>% summarise(median(sports_balls)) #median number of sports balls picked up in 2016 was 26

nrow(precip_stack) #24 observations
precip_stack %>% filter(year == "2017") %>% summarise(sum(total)) #32.93 inches of rain total
```

#Problem 3
```{r}
brfss_data <- p8105.datasets::brfss_smart2010 %>%
  janitor::clean_names() %>%
  rename(state = locationabbr, county = locationdesc) %>%
  filter(topic == "Overall Health") %>%
  select(-(class:question), -sample_size, -(confidence_limit_low:geo_location))
  #import and clean data, filter topic, exclude variables

brfss_data <- brfss_data %>%
  spread(key = response, value = data_value) %>%
  janitor::clean_names() %>%
  mutate(p_excellent_vgood = (excellent + very_good) / (excellent + very_good + good + fair + poor))
#make each response type its own column, clean names, add variable that is the proportion of excellent and very good responses.


nrow(distinct(brfss_data, county)) #404 distinct locations designated by county
nrow(distinct(brfss_data, state)) #51 states - includes DC

count(brfss_data, state) %>%
  filter(n == max(n)) #New Jersey has the most entries - 146

brfss_data %>% 
  filter(year == "2002") %>%
  summarise(median(excellent, na.rm = TRUE)) #median of excellent responses in 2002 is 23.6.

brfss_data %>%
  filter(year == "2002") %>%
  ggplot(aes(x = excellent)) +
  geom_histogram(binwidth = 0.5) +
  labs(x = "Excellent", y = "frequency", title = "Excellent responses in 2002")

brfss_data %>%
  filter(county %in% c("NY - Queens County", "NY - New York County")) %>%
  mutate(p_excellent = excellent /  (excellent + very_good + good + fair + poor)) %>% 
  ggplot(aes(x = year, y = p_excellent, color = county)) +
  geom_point(size = 3) +
  labs(x = "Year", y = "proportion", caption = "Proportion of excellent responses in Queens and NY Counties, 2002-2010")
  viridis::scale_color_viridis(
    labels = c("Queens County", "New York County"),
    discrete = TRUE
  )

```



